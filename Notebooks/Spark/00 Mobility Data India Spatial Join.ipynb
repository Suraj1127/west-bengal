{"cells":[{"cell_type":"markdown","source":["# Spark notebook for doing spatial join of GIS points with admins"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c51eb3b7-4ebb-487c-a8f8-aaaa6c5d9685"}}},{"cell_type":"markdown","source":["## Installation and setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"65d8e86a-0fb0-4098-934d-32002d3fdc99"}}},{"cell_type":"code","source":["# installing the python packages using pip\n!pip install pandas\n!pip install numpy\n!pip install geopandas\n!pip install descartes\n!pip install fiona\n!pip install shapely\n!pip install pyproj\n!pip install matplotlib\n!pip install pyspark\n!pip install geospark\n\n# importing the required python packages\nimport time\nimport datetime\n\nimport pandas as pd\nimport geopandas as gp\n\nfrom pyspark.sql import SparkSession\n\nfrom geospark.register import upload_jars\nfrom geospark.register import GeoSparkRegistrator\n\nupload_jars() # necessary to load in GeoSpark libraries manually installed to the server\n\nspark = SparkSession.builder.getOrCreate()\n\nGeoSparkRegistrator.registerAll(spark)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1ea5018d-2ddc-4040-b4bb-014ef1e075bb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[1]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[1]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# import a more extensive list of pySpark and GeoSpark packages\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\nimport pyspark.sql.functions as fs\nfrom pyspark.sql import SQLContext\nfrom pyspark import SparkContext\nfrom pyspark.sql.functions import count\nfrom pyspark.sql.functions import col, countDistinct\nfrom pyspark import SparkContext\n\nimport pylab as plt\nfrom pyspark.sql.functions import lag\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.functions import acos, cos, sin, lit, toRadians\n\nimport geospark\nfrom geospark.register import GeoSparkRegistrator\nfrom geospark.utils import GeoSparkKryoRegistrator, KryoSerializer\nfrom geospark.register import upload_jars\nfrom geospark.core.formatMapper.shapefileParser import ShapefileReader\nfrom geospark.core import SpatialRDD"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b585e3f-bd7f-4903-a576-9a1e038cdb59"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# these help optimize the operations of Spark\n\nspark.conf.set(\"spark.sql.shuffle.partitions\", 1000)\nspark.conf.set(\"spark.network.timeout\", 1000)\nspark.conf.set(\"spark.driver.memory\", 20)\n# spark.conf.set(\"spark.driver.cores\", 20) # appears unnecessary with autoscale\nspark.conf.set(\"spark.driver.maxResultSize\", 10)\nspark.conf.set(\"spark.serializer\", KryoSerializer.getName)\nspark.conf.set(\"spark.kryo.registrator\", GeoSparkKryoRegistrator.getName)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14dafcc8-74be-4303-ac9a-651225b46e64"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n\nimport com.vividsolutions.jts.geom.{Coordinate, Geometry, GeometryFactory}\nimport org.datasyslab.geospark.formatMapper.shapefileParser.ShapefileReader\nimport org.datasyslab.geospark.spatialRDD.SpatialRDD\nimport org.datasyslab.geosparksql.utils.{Adapter, GeoSparkSQLRegistrator}\nGeoSparkSQLRegistrator.registerAll(sqlContext)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fa62789b-b211-4e52-9189-7164841a6172"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">import com.vividsolutions.jts.geom.{Coordinate, Geometry, GeometryFactory}\nimport org.datasyslab.geospark.formatMapper.shapefileParser.ShapefileReader\nimport org.datasyslab.geospark.spatialRDD.SpatialRDD\nimport org.datasyslab.geosparksql.utils.{Adapter, GeoSparkSQLRegistrator}\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">import com.vividsolutions.jts.geom.{Coordinate, Geometry, GeometryFactory}\nimport org.datasyslab.geospark.formatMapper.shapefileParser.ShapefileReader\nimport org.datasyslab.geospark.spatialRDD.SpatialRDD\nimport org.datasyslab.geosparksql.utils.{Adapter, GeoSparkSQLRegistrator}\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Read shapefiles and mobility data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"18eaac31-0471-4c92-a548-7b36d0026d09"}}},{"cell_type":"code","source":["# let's read admin3 and admin5 shapefiles from the GeoPackage\nadmin3 = gp.read_file(\"/dbfs/mnt/CUBEIQ/esapv/India_Administrative_Boundaries.gpkg\",layer=\"Admin3\")\nadmin5 = gp.read_file(\"/dbfs/mnt/CUBEIQ/esapv/India_Administrative_Boundaries.gpkg\",layer=\"Admin5_TownVillageWard\")\n\n# load the whole cubeiq data into spark dataframe\ndata_path = ''\nsdf = spark.read.format('delta').load(data_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aee20987-8b6e-4373-8e12-939a623318ca"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"sdf","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"device_id","nullable":true,"type":"string"},{"metadata":{},"name":"device_os","nullable":true,"type":"string"},{"metadata":{},"name":"timestamp","nullable":true,"type":"integer"},{"metadata":{},"name":"date","nullable":true,"type":"string"},{"metadata":{},"name":"lat","nullable":true,"type":"double"},{"metadata":{},"name":"lon","nullable":true,"type":"double"},{"metadata":{},"name":"accuracy","nullable":true,"type":"float"},{"metadata":{},"name":"country","nullable":true,"type":"string"},{"metadata":{},"name":"_classification_type","nullable":true,"type":"string"},{"metadata":{},"name":"_transformation_type","nullable":true,"type":"string"},{"metadata":{},"name":"__date_local","nullable":true,"type":"string"},{"metadata":{},"name":"__hr_local","nullable":true,"type":"string"},{"metadata":{},"name":"__is_night_local","nullable":true,"type":"boolean"}],"type":"struct"},"tableIdentifier":"dbfs:/mnt/CUBEIQ/delta/cubeiq_1"}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Convert latitude and longitudes to GIS points"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8532f8ed-d93b-442c-86ac-4133d0f668fd"}}},{"cell_type":"code","source":["# register sdf spark dataframe as sdf_ tempview\nsdf.createOrReplaceTempView('sdf_')\n\n# converting the long and lat columns into Point(X, Y) column using geospark\npoints = spark.sql(\"SELECT sdf_.device_id, sdf_.timestamp, ST_Point(CAST(sdf_.lon AS Decimal(24,20)),CAST(sdf_.lat AS Decimal(24,20))) AS geometry FROM sdf_\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"52dd3693-c0d3-4da8-bc18-d7355e0509cb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"points","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"device_id","nullable":true,"type":"string"},{"metadata":{},"name":"timestamp","nullable":true,"type":"integer"},{"metadata":{},"name":"geometry","nullable":false,"type":{"class":"org.apache.spark.sql.geosparksql.UDT.GeometryUDT","pyClass":"geospark.sql.types.GeometryType","sqlType":{"containsNull":false,"elementType":"byte","type":"array"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Create spark dataframe from geodataframe"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea24a908-2e18-46a6-bc6e-735330b24491"}}},{"cell_type":"code","source":["# Enable Arrow-based columnar data transfer for speeding up this process\n# Interestingly this operation can NOT make use of additional workers, which is why it takes around ~45 minutes to convert Admin3 and Admin5 to dataframes\n# admin5 takes considerably more time\n\nspark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n\n# Creating spark dataframes from the geopandas GeoDataFrames\n\nadmin3 = spark.createDataFrame(\n    admin3[['L3_CODE', 'geometry']]\n  )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8b6edb31-af5b-4a53-b195-006a0492e792"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"admin3","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"L3_CODE","nullable":true,"type":"long"},{"metadata":{},"name":"geometry","nullable":true,"type":{"class":"org.apache.spark.sql.geosparksql.UDT.GeometryUDT","pyClass":"geospark.sql.types.GeometryType","sqlType":{"containsNull":false,"elementType":"byte","type":"array"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Data filtering and spatial join"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd10d78f-a995-4b02-8280-0642a1324ad2"}}},{"cell_type":"code","source":["# now register spark dataframes as tables\nsqlContext.registerDataFrameAsTable(points, \"points\")\nsqlContext.registerDataFrameAsTable(admin3, \"admin3_tbl\")\n# sqlContext.registerDataFrameAsTable(admin5, \"admin5_tbl\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8f4d4aa4-9646-4307-9358-183d3d15ed6e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# here data can be filtered using some date range; this is optional\nfrom_ = \"01/01/2020\"\nto_ = \"07/07/2020\"\n\nfrom_ = time.mktime(datetime.datetime.strptime(from_, \"%d/%m/%Y\").timetuple())\nto_ = time.mktime(datetime.datetime.strptime(to_, \"%d/%m/%Y\").timetuple())\n\ntimestamps = (from_, to_)\npoints1 = points.where(col('timestamp').between(*timestamps))\n\n# now register this as a table\nsqlContext.registerDataFrameAsTable(points1, \"pts_filter_tbl\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"414bde02-0295-4c91-b17e-de2e4b8e51ab"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"points1","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"device_id","nullable":true,"type":"string"},{"metadata":{},"name":"timestamp","nullable":true,"type":"integer"},{"metadata":{},"name":"geometry","nullable":false,"type":{"class":"org.apache.spark.sql.geosparksql.UDT.GeometryUDT","pyClass":"geospark.sql.types.GeometryType","sqlType":{"containsNull":false,"elementType":"byte","type":"array"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# spatial join for adm3\nintersect_query_adm3 =  \"\"\"\n        SELECT s.L3_CODE, p.device_id, p.timestamp, p.geometry \n        FROM pts_filter_tbl AS p, admin3_tbl AS s \n        WHERE ST_Intersects(p.geometry, s.geometry)\n\"\"\"\n\nspatial_join_result = spark.sql(intersect_query_adm3)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"31385af7-db71-4159-8492-de5af8acc45d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"spatial_join_result","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"L3_CODE","nullable":true,"type":"long"},{"metadata":{},"name":"device_id","nullable":true,"type":"string"},{"metadata":{},"name":"timestamp","nullable":true,"type":"integer"},{"metadata":{},"name":"geometry","nullable":false,"type":{"class":"org.apache.spark.sql.geosparksql.UDT.GeometryUDT","pyClass":"geospark.sql.types.GeometryType","sqlType":{"containsNull":false,"elementType":"byte","type":"array"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# registering the spatial tables\nsqlContext.registerDataFrameAsTable(spatial_join_result, \"sjr_tbl\")\n# sqlContext.registerDataFrameAsTable(admin5, \"admin5_tbl\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a6efd9e-57fd-4122-9dfd-c26e28ec023c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Export"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"23e285ff-7714-4574-9c85-51abdc354885"}}},{"cell_type":"code","source":["# Exporting spatial join results as a delta table we can access at any time\n# Partitioning by L3 CODE for sanity's sake\n# Based off here https://docs.databricks.com/delta/intro-notebooks.html\nexport_path = ''\nspatial_join_result.write.format(\"delta\").mode(\"overwrite\").partitionBy(\"L3_CODE\").save(export_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e2cf86e6-47fa-4a1f-8d3a-a6c29565db8d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"00 Mobility Data India Spatial Join","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2469475273998204}},"nbformat":4,"nbformat_minor":0}
